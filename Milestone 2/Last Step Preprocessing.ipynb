{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = pd.read_csv('imdb_tmdb_correctids_0_36000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "mismatch_sarah = []\n",
    "mismatch_laura = []\n",
    "sarahs_mismatch = 0\n",
    "laura_mismatch = 0\n",
    "for index, row in full_dataset.iterrows():\n",
    "    try:\n",
    "        if row['title_x'].lower() != row['title_y'].lower():\n",
    "            \n",
    "            if row['imdb_id'] in sarahs_ids:\n",
    "                sarahs_mismatch += 1\n",
    "                mismatch_sarah.append([row['imdb_id'],row['title_x'],row['title_y']])\n",
    "            else:\n",
    "                laura_mismatch += 1\n",
    "                mismatch_laura.append([row['imdb_id'],row['title_x'],row['title_y']])\n",
    "    except:\n",
    "        if row['title_x'] != row['title_y']:\n",
    "            if row['imdb_id'] in sarahs_ids:\n",
    "                sarahs_mismatch += 1\n",
    "                mismatch_sarah.append([row['imdb_id'],row['title_x'],row['title_y']])\n",
    "            else:\n",
    "                laura_mismatch += 1\n",
    "                mismatch_laura.append([row['imdb_id'],row['title_x'],row['title_y']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##bag of words on title\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "titles = []\n",
    "for i in full_dataset['title_x']:\n",
    "    try:\n",
    "        title_words.append(i.decode('utf-8'))\n",
    "        titles.append(i)\n",
    "    except:\n",
    "        titles.append(0)\n",
    "        \n",
    "#remove movies that have non-ascii titles, I ran into lots of problems with this so we\n",
    "#decided to just delete these movies\n",
    "full_dataset['title_x'] = titles\n",
    "full_dataset = full_dataset[full_dataset['title_x'] != 0] \n",
    "\n",
    "title_words = []\n",
    "for i in full_dataset['title_x']:\n",
    "    title_words.append(i)\n",
    "\n",
    "#run bag of words and keep 100 features \n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_features = 100)\n",
    "data_features = vectorizer.fit_transform(title_words).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#give informative column names \n",
    "feature_names = ['title_'+i.encode('utf-8') for i in vectorizer.get_feature_names()]\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    full_dataset[feature_names[i]] = data_features[:,i]\n",
    "del full_dataset['title_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on Overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "overview_words = []\n",
    "for i in full_dataset['overview']:\n",
    "    try:\n",
    "        overview_words.append(i.decode('utf-8'))\n",
    "    except:\n",
    "        overview_words.append('')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_features = 100)\n",
    "overview_data_features = vectorizer.fit_transform(overview_words).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overview_feature_names = ['overview_'+i.encode('utf-8') for i in vectorizer.get_feature_names()]\n",
    "for i in range(len(overview_feature_names)):\n",
    "    full_dataset[overview_feature_names[i]] = overview_data_features[:,i]\n",
    "del full_dataset['overview']\n",
    "full_dataset.to_csv('dataset_bag_of_words.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal With Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_genres =  ['Action', 'Adventure', 'Adult', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Thriller', 'War', 'Western', 'Talk-Show', 'News', 'Game-Show', 'Reality-TV', 'History', 'Sport']\n",
    "for i in current_genres:\n",
    "    del full_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acceptable_genres = ['Action','Adventure','Animation','Comedy','Crime','Documentary','Drama','Family','Fantasy','History','Horror','Mystery','Romance','Science Fiction','Thriller','War','Western']\n",
    "new_genres = []\n",
    "for i in acceptable_genres:\n",
    "    new_genres.append([])\n",
    "\n",
    "for index, row in full_dataset.iterrows():\n",
    "    \n",
    "    #x genres\n",
    "    gen_x = row['genres_x']\n",
    "    genre_x = []\n",
    "    try:\n",
    "        g1 = gen_x.replace(\"]\", \"\")\n",
    "        g1 = g1.replace(\"[\", \"\")\n",
    "        g1 = g1.split(',')\n",
    "        for c in g1:\n",
    "            c = c[c.index('\\''):]\n",
    "            c = c.strip('\\'')\n",
    "            genre_x.append(c)\n",
    "            if c == 'Sci-Fi':\n",
    "                c = 'Science Fiction'\n",
    "    except:\n",
    "        g1 = []\n",
    "    \n",
    "    #y genres\n",
    "    gen_y = row['genres_y']\n",
    "    genre_y = []\n",
    "    try:\n",
    "        g2 = gen_y.replace(\"]\", \"\")\n",
    "        g2 = g2.replace(\"[\", \"\")\n",
    "        g2 = g2.split(',')\n",
    "        for c in g2:\n",
    "            c = c[c.index('\\''):]\n",
    "            c = c.strip('\\'')\n",
    "            if c == 'Sci-Fi':\n",
    "                c = 'Science Fiction'\n",
    "            genre_y.append(c)\n",
    "    except:\n",
    "        g2 = []\n",
    "    \n",
    "    \n",
    "    intersection =  list(set(genre_y).intersection(genre_x))\n",
    "    \n",
    "    if intersection == []:\n",
    "        for g in range(len(acceptable_genres)):\n",
    "            new_genres[g].append('Drop')\n",
    "        \n",
    "    else:\n",
    "        for g in range(len(acceptable_genres)):\n",
    "            if acceptable_genres[g] in intersection:\n",
    "                new_genres[g].append(1)\n",
    "            else:\n",
    "                new_genres[g].append(0)\n",
    "    \n",
    "\n",
    "#delete rows with no genre information\n",
    "for i in range(len(acceptable_genres)):\n",
    "    full_dataset[acceptable_genres[i]] = new_genres[i]\n",
    "    \n",
    "full_dataset_new = full_dataset[full_dataset['Adventure'] != 'Drop']\n",
    "\n",
    "#delte genre columns\n",
    "del full_dataset_new['genres_x']\n",
    "del full_dataset_new['genres_y']\n",
    "\n",
    "full_dataset_new.to_csv('dataset_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## delete id, title_y, imdb_id, movie_id, Unnamed: 0\n",
    "import numpy as np\n",
    "del full_dataset_new['id']\n",
    "del full_dataset_new['title_y']\n",
    "del full_dataset_new['imdb_id']\n",
    "del full_dataset_new['movie_id']\n",
    "del full_dataset_new['Unnamed: 0']\n",
    "\n",
    "full_dataset_new.replace(r'\\s+', np.nan, regex=True)\n",
    "\n",
    "full_dataset_new.to_csv('dataset_final.csv', index = False, na_rep = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
