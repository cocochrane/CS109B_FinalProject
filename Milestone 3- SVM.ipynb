{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools as it\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "## Split Into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(dataset)\n",
    "X_labels = labels[:-17]\n",
    "Y_labels = labels[-17:]\n",
    "\n",
    "data = dataset.as_matrix()[:,:] \n",
    "\n",
    "Y = data[:, -17:]\n",
    "X = data[:,0:-17]\n",
    "\n",
    "training_set_X, test_set_X, training_set_Y, test_set_Y = train_test_split(\n",
    "    X, Y, test_size=0.20)\n",
    "\n",
    "X_train = pd.DataFrame(data=training_set_X[:,:],  \n",
    "                 columns=X_labels)  \n",
    "\n",
    "X_test = pd.DataFrame(data=test_set_X[:,:],  \n",
    "                 columns=X_labels)  \n",
    "\n",
    "Y_train = pd.DataFrame(data=training_set_Y[:,:],  \n",
    "                 columns=Y_labels)  \n",
    "\n",
    "Y_test = pd.DataFrame(data=test_set_Y[:,:],  \n",
    "                 columns=Y_labels)  \n",
    "\n",
    "X_train.to_csv(\"X_train.csv\", index = False, na_rep = np.nan)\n",
    "X_test.to_csv(\"X_test.csv\", index = False, na_rep = np.nan)\n",
    "Y_train.to_csv(\"Y_train.csv\", index = False, na_rep = np.nan)\n",
    "Y_test.to_csv(\"Y_test.csv\", index = False, na_rep = np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## Impute Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for column in X_train:\n",
    "    X_train[column] = X_train[column].apply(pd.to_numeric)\n",
    "\n",
    "    #if this is a categorical column\n",
    "    if np.array_equal(X_train[column].unique(),[0,1]):\n",
    "        X_train[column] = X_train[column].replace(np.nan, X_train[column].value_counts()[0])\n",
    "        X_test[column] = X_test[column].replace(np.nan, X_train[column].value_counts()[0])\n",
    "\n",
    "    else: #if numerical column\n",
    "        X_train[column] = X_train[column].replace(np.nan, X_train[column].median()) \n",
    "        X_test[column] = X_test[column].replace(np.nan, X_train[column].median()) \n",
    "          \n",
    "X_train.to_csv(\"ImputedX_train.csv\", index = False)\n",
    "X_test.to_csv(\"ImputedX_test.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "## Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"ImputedX_train.csv\", delimiter=\",\", skiprows = 1)\n",
    "X_test = np.loadtxt(\"ImputedX_test.csv\", delimiter=\",\", skiprows = 1)\n",
    "X_train = normalize(X_train, axis = 0)\n",
    "X_test = normalize(X_test, axis = 0)\n",
    "\n",
    "pca = PCA(n_components = 0.90)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['PCA'+str(i) for i in range(len(pca.explained_variance_))]\n",
    "\n",
    "X_test = pd.DataFrame(data=X_test_pca[:,:],  \n",
    "                 columns=labels)  \n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train_pca[:,:],  \n",
    "                 columns=labels)  \n",
    "\n",
    "X_train.to_csv(\"X_train_pca.csv\", index = False)\n",
    "X_test.to_csv(\"X_test_pca.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "## Apply SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuneHyperparameters(classifier, training_set_X, training_set_Y, hyperparameters, number_of_folds):\n",
    "    \"\"\"This function runs k-fold cross validation on given set of parameters and returns best combo of parameters\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    -classifier: base classifer, parameters will be set during this function\n",
    "    -training_set_X: X data\n",
    "    -training_set_Y: Y data\n",
    "    -hyperparameters: dictionary of parameter name to options\n",
    "    -number_of_folds: number of k-fold folds\n",
    "    \n",
    "    Returns: \n",
    "    -------\n",
    "    Dictionary of best parameter values, for example {'C': 2, 'penalty': 'l2'}\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    parameters = {'C': [3,2,5,6], 'penalty': ['l2']}\n",
    "    tuneHyperparameters(LogisticRegression(), X, Y, parameters, 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    kf = KFold(n_splits= number_of_folds)\n",
    "    kf.get_n_splits(training_set_X)\n",
    "    \n",
    "    allNames = sorted(hyperparameters)\n",
    "    parameter_combos = it.product(*(hyperparameters[Name] for Name in allNames))\n",
    "    \n",
    "    metrics = []\n",
    "    params = []\n",
    "    for hyperparameter_combo in parameter_combos:\n",
    "        params.append(hyperparameter_combo)\n",
    "        for p in range(len(allNames)):\n",
    "            classifier.set_params(**{allNames[p]: hyperparameter_combo[p]})\n",
    "        f1_score = []\n",
    "        for train_index, test_index in kf.split(training_set_X):\n",
    "            X_train, X_validation = training_set_X[train_index], training_set_X[test_index]\n",
    "            Y_train, Y_validation = training_set_Y[train_index], training_set_Y[test_index]\n",
    "\n",
    "            classifier.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = classifier.predict(X_validation)\n",
    "            prec, rec, f1, sup = precision_recall_fscore_support(Y_validation, y_pred, average= \"binary\")\n",
    "            acc = accuracy_score(Y_validation, y_pred)\n",
    "            f1_score.append(f1)\n",
    "            \n",
    "        metrics.append(sum(f1_score)/float(len(f1_score))) \n",
    "    \n",
    "    best_params = params[metrics.index(max(metrics))]\n",
    "    print max(metrics)\n",
    "    return {allNames[i]: best_params[i] for i in range(len(best_params))}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(\"X_train_pca.csv\", delimiter=\",\", skiprows = 1)\n",
    "X_test = np.loadtxt(\"X_test_pca.csv\", delimiter=\",\", skiprows = 1)\n",
    "#X_train = np.loadtxt(\"ImputedX_train.csv\", delimiter=\",\", skiprows = 1)\n",
    "#X_test = np.loadtxt(\"ImputedX_test.csv\", delimiter=\",\", skiprows = 1)\n",
    "Y_train = np.loadtxt(\"Y_train.csv\", delimiter=\",\", skiprows = 1)\n",
    "Y_test = np.loadtxt(\"Y_test.csv\", delimiter=\",\", skiprows = 1)\n",
    "\n",
    "#X_train = normalize(X_train, axis = 0)\n",
    "#X_test = normalize(X_test, axis = 0)\n",
    "\n",
    "genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Mystery', 'Romance', 'Science Fiction', 'Thriller', 'War', 'Western']\n",
    "\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    print \"genre is:\", genres[i]\n",
    "    Y_curr = Y_train[:,i]\n",
    "    #print tuneHyperparameters(SVC(), X_train, Y_curr, {'class_weight':['balanced'],'C':[0.001,0.1,1],'kernel':['linear']}, 5)\n",
    "    print tuneHyperparameters(SVC(), X_train, Y_curr, {'class_weight':['balanced'],'C':[1,2],'kernel':['linear']}, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre is: Action\n",
      "0.265372168285\n",
      "genre is: Adventure\n",
      "0.147477360931\n",
      "genre is: Animation\n",
      "0.400606980273\n",
      "genre is: Comedy\n",
      "0.447845804989\n",
      "genre is: Crime\n",
      "0.202496532594\n",
      "genre is: Documentary\n",
      "0.487804878049\n",
      "genre is: Drama\n",
      "0.57538849223\n",
      "genre is: Family\n",
      "0.196428571429\n",
      "genre is: Fantasy\n",
      "0.0808344198175\n",
      "genre is: History\n",
      "0.0364188163885\n",
      "genre is: Horror\n",
      "0.278330019881\n",
      "genre is: Mystery\n",
      "0.107142857143\n",
      "genre is: Romance\n",
      "0.273704789834\n",
      "genre is: Science Fiction\n",
      "0.166666666667\n",
      "genre is: Thriller\n",
      "0.242990654206\n",
      "genre is: War\n",
      "0.137614678899\n",
      "genre is: Western\n",
      "0.615384615385\n"
     ]
    }
   ],
   "source": [
    "c_param = [1,1,1,2,1,1,2,1,1,1,1,1,1,1,1,1,0.1]\n",
    "y_predictions = []\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    print \"genre is:\", genres[i]\n",
    "    Y_curr = Y_train[:,i]\n",
    "    Y_test_curr = Y_test[:,i]\n",
    "    \n",
    "    svm = SVC(class_weight = 'balanced', C = c_param[i], kernel = 'linear')\n",
    "    svm.fit(X_train, Y_curr)\n",
    "\n",
    "    y_pred = svm.predict(X_test)\n",
    "    prec, rec, f1, sup = precision_recall_fscore_support(Y_test_curr, y_pred, average= \"binary\")\n",
    "    print f1\n",
    "    y_predictions.append(y_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23024371843500493"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matrix(y_predictions)\n",
    "a = np.transpose(a)\n",
    " \n",
    "hamming_loss(Y_test, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "# Sample Data For Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre is: Action\n",
      "0.284886958077\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 5, 'class_weight': 'balanced'}\n",
      "genre is: Adventure\n",
      "0.115759726816\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 1, 'class_weight': 'balanced'}\n",
      "genre is: Animation\n",
      "0.405414984711\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n",
      "genre is: Comedy\n",
      "0.405489071525\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 1, 'class_weight': 'balanced'}\n",
      "genre is: Crime\n",
      "0.187542073798\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 5, 'class_weight': 'balanced'}\n",
      "genre is: Documentary\n",
      "0.468122693662\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n",
      "genre is: Drama\n",
      "0.552402109197\n",
      "{'kernel': 'rbf', 'C': 0.001, 'gamma': 0.001, 'class_weight': 'balanced'}\n",
      "genre is: Family\n",
      "0.18140493057\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 1, 'class_weight': 'balanced'}\n",
      "genre is: Fantasy\n",
      "0.103621650239\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n",
      "genre is: History\n",
      "0.0392344497608\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 1, 'class_weight': 'balanced'}\n",
      "genre is: Horror\n",
      "0.255312846114\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 5, 'class_weight': 'balanced'}\n",
      "genre is: Mystery\n",
      "0.103233352198\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n",
      "genre is: Romance\n",
      "0.263435523423\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n",
      "genre is: Science Fiction\n",
      "0.140042436574\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 1, 'class_weight': 'balanced'}\n",
      "genre is: Thriller\n",
      "0.240728968002\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 5, 'class_weight': 'balanced'}\n",
      "genre is: War\n",
      "0.166666666667\n",
      "{'kernel': 'rbf', 'C': 0.1, 'gamma': 5, 'class_weight': 'balanced'}\n",
      "genre is: Western\n",
      "0.468710828813\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.1, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "X_train = np.loadtxt(\"X_train_pca.csv\", delimiter=\",\", skiprows = 1)\n",
    "X_test = np.loadtxt(\"X_test_pca.csv\", delimiter=\",\", skiprows = 1)\n",
    "Y_train = np.loadtxt(\"Y_train.csv\", delimiter=\",\", skiprows = 1)\n",
    "Y_test = np.loadtxt(\"Y_test.csv\", delimiter=\",\", skiprows = 1)\n",
    "\n",
    "\n",
    "genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Mystery', 'Romance', 'Science Fiction', 'Thriller', 'War', 'Western']\n",
    "sample_size = X_train.shape[0]/5\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    print \"genre is:\", genres[i]\n",
    "    \n",
    "    s = np.random.choice(X_train.shape[0], sample_size, replace=False)\n",
    "    X_train_sample = X_train[s, :]\n",
    "    Y_curr = Y_train[s, i]\n",
    "    print tuneHyperparameters(SVC(), X_train_sample, Y_curr, {'class_weight':['balanced'],'C':[0.001,0.1,1,10],'kernel':['rbf'],'gamma':[0.001,0.1,1,5]}, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre is: Action\n",
      "0.232227488152\n",
      "genre is: Adventure\n",
      "0.138020833333\n",
      "genre is: Animation\n",
      "0.394736842105\n",
      "genre is: Comedy\n",
      "0.450346420323\n",
      "genre is: Crime\n",
      "0.196923076923\n",
      "genre is: Documentary\n",
      "0.479204339964\n",
      "genre is: Drama\n",
      "0.542196831992\n",
      "genre is: Family\n",
      "0.211731044349\n",
      "genre is: Fantasy\n",
      "0.0918114143921\n",
      "genre is: History\n",
      "0.0280811232449\n",
      "genre is: Horror\n",
      "0.290976058932\n",
      "genre is: Mystery\n",
      "0.0974212034384\n",
      "genre is: Romance\n",
      "0.267168391345\n",
      "genre is: Science Fiction\n",
      "0.168498168498\n",
      "genre is: Thriller\n",
      "0.266875981162\n",
      "genre is: War\n",
      "0.152249134948\n",
      "genre is: Western\n",
      "0.316784869976\n"
     ]
    }
   ],
   "source": [
    "c_param = [(1,5),(1,1),(10,0.1),(1,1),(1,5),(10,0.1),(0.001,0.001),(1,1),(10,0.1),(1,1),(10,5),(10,0.1),(10,0.1),(1,1),(10,5),(0.1,5),(10,0.1)]\n",
    "y_predictions = []\n",
    "\n",
    "for i in range(len(genres)):\n",
    "    print \"genre is:\", genres[i]\n",
    "    Y_curr = Y_train[:,i]\n",
    "    Y_test_curr = Y_test[:,i]\n",
    "    \n",
    "    svm = SVC(class_weight = 'balanced', C = c_param[i][0], gamma = c_param[i][1], kernel = 'rbf')\n",
    "    svm.fit(X_train, Y_curr)\n",
    "\n",
    "    y_pred = svm.predict(X_test)\n",
    "    prec, rec, f1, sup = precision_recall_fscore_support(Y_test_curr, y_pred, average= \"binary\")\n",
    "    print f1\n",
    "    y_predictions.append(y_pred)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22881870952869926"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "a = np.matrix(y_predictions)\n",
    "a = np.transpose(a)\n",
    " \n",
    "hamming_loss(Y_test, a)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
